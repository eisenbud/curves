\documentclass[12pt, leqno]{book}
\usepackage{amsmath,amscd,amsthm,amssymb,amsxtra,latexsym,epsfig,epic,graphics}
\usepackage[matrix,arrow,curve]{xy}
\usepackage{graphicx}
\usepackage{diagrams}
%\usepackage{amsrefs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\textwidth16cm
%\textheight20cm
%\topmargin-2cm
\oddsidemargin.8cm
\evensidemargin1cm

%%%%%Definitions
\input preamble.tex
\input style-for-curves.sty
\def\TU{{\bf U}}
\def\AA{{\mathbb A}}
\def\BB{{\mathbb B}}
\def\CC{{\mathbb C}}
\def\QQ{{\mathbb Q}}
\def\RR{{\mathbb R}}
\def\facet{{\bf facet}}
\def\image{{\rm image}}
\def\cE{{\cal E}}
\def\cF{{\cal F}}
\def\cG{{\cal G}}
\def\cH{{\cal H}}
\def\cHom{{{\cal H}om}}
\def\h{{\rm h}}
 \def\bs{{Boij-S\"oderberg{} }}

\makeatletter
\def\Ddots{\mathinner{\mkern1mu\raise\p@
\vbox{\kern7\p@\hbox{.}}\mkern2mu
\raise4\p@\hbox{.}\mkern2mu\raise7\p@\hbox{.}\mkern1mu}}
\makeatother

%%
%\pagestyle{myheadings}
\date{April 30, 2018}
%\date{}
\title{Curves}
%{\normalsize ***Preliminary Version***}} 
\author{David Eisenbud and Joe Harris }

\begin{document}

\chapter{Background}
\section*{Outline}
 Background (corresponds to material in Hartshorne Ch 4, sects 1,2,4(?)---all except elliptic curves and ``classification")
\begin{enumerate}

\item Lasker's Theorem (complete intersections are unmixed) -- sometimes incorrectly called ``$AF+BG$''
state ci implies unmixed; prove by $H^1$ of line bundle.

\item B\'ezout and the  weak B\'ezout (ex 8.4.6 in Fulton).
B\'ezout via Koszul complex, at least in codim 2.

\item Families. Define families. discuss "good and bad" families. example: symmetric product. example: plane curves of degree d. family of line bundles on a curve (or a family of curves.)


\end{enumerate}


\section{The Lasker-Noether Theorem}

A key element in the algebraic study of plane curves initiated by Brill and Noether following Riemann's discoveries was what Noether named the ``Fundamental Lemma on Holomorphic Functions.'' In the original language it said that if the homogeneous forms $F(x_{0},x_{1},x_{2})=0$ and $G(x_{0},x_{1},x_{2})=0$ are the equations of two curves in $\PP^{2}$ that have no component in common, then any form $H$ that locally represents a function (the ``holomorphic functions'' of the name) vanishing on all the points
of the intersection must have an expression $H = AF+BG$, where $A,B$ are also homogeneous forms. It was extended by Lasker to the case of many polynomials (homogeneous or not) in many variables. (This is sometimes called the ``$AF+BG$ Theorem''.) 

\begin{theorem}\label{Lasker}
Suppose that $I = (f_{1}, \dots, f_{c}) \subsetneq S:=\CC[x_{0},\dots,x_{n}]$ is an ideal generated by $c$ homogeneous forms in a polynomial ring. 
If $X:= V(I)$ has codimension $c$, then $I$ is saturated and $\HH^{i}(\cO_{X}(d)) = 0$ for all $0<i<\dim X$ and all $d\in \ZZ$; and if $\dim X\geq 1$
then the map
$\HH^{0}(\cO_{\PP^{n}}(d)) \to \HH^{0}(\cO_{X}(d))$ is surjective for every $d$.
\end{theorem}

By the Principal Ideal Theorem(\cite[Theorem ***]{Eisenbud95} the codimension of $V(f_{1},\dots, f_{c})$ is at most $c$;
the Theorem thus covers the case where the codimension is ``as large as possible'', that is, the $V(f_{i})$ meet eachother
in a dimensionally transverse way.

In modern language, the conclusion says that the ring $S/I$ is Cohen-Macaulay. See for example \cite[Chapter 18]{Eisenbud95}, where the result it proven in greater generality.

Theorem~\ref{Lasker} immediately implies the orginal version of the theorem because (by the Nullstellensatz) the set of forms vanishing on $V(f_{1}, \dots, f_{c})$ is the saturation 
of the ideal $(f_{1}, \dots, f_{c})$. 

We will make use of the following algebraic Lemma, proven in  in \cite[Theorem 18.***]{Eisenbud95}:

\begin{lemma}\label{Cohen-Macaulay}
 Under the hypothesis of Theorem~\ref{Lasker}, the polynomial $f_{i}$ is a nonzerodivisor in the ring 
$S/(f_{1}, \dots, f_{i-1})$ for $i = 1, \dots, c$.
\end{lemma}

The conclusion is usually stated by saying that   $f_{1}, \dots, f_{c}$ is a \emph{regular sequence}.

\begin{proof}[Partial Proof]
 The result is obvious for $c=1$. For $c=2$ the hypothesis implies that $f_{1}$ and $f_{2}$ have no common factor.
If $g f_{2} \equiv 0\ {\rm mod}\ f_{1}$ then, since $S$ has unique prime factorization, $g$ must be divisible by
$f_{1}$, that is, $g  \equiv 0\ {\rm mod}\ f_{1}$, proving the result for $c=2$. In general, the result is equivalent to the 
statement that $S$ is a Cohen-Macaulay ring,  \cite[Proposition 18.9]{Eisenbud95}.
\end{proof}


\begin{proof} [Proof of Theorem~\ref{Lasker}] We do induction on $c$. For $c=0$ the saturation is trivial, and the vanishing in the case $c=0$ is the usual computation of the cohomology of line bundles on $\PP^{n}$. 

Now suppose that the theorem is true for $X' := (f_{1}, \dots f_{c-1})$. Note that $\dim X' = n-c+1\geq 1$.
 The surjectivity of 
the maps $\HH^{0}(\cO_{\PP^{n}}(d)) \to \HH^{0}(\cO_{X'}(d))$ shows that the homogeneous coordinate ring
of $X'$ is $R':=\oplus_{d} \HH^{0}(\cO_{X'}(d))$.

Write $e$ for the degree of $f_{c}$ . By Lemma~\ref{Cohen-Macaulay} there is a short
exact sequence
$$
0\to \cO_{X'}(-e) \rTo^{f_{c}} \cO_{X'} \to \cO_{X} \to 0.
$$
Tensoring with $\cO_{\PP^{n}}(d)$, and passing to cohomology, we obtain a long exact sequence that begins
\begin{align*}
0\to &\HH^{0}(\cO_{X'}(d-e_{1})) \rTo^{f_{1}}  \HH^{0}(\cO_{X'}(d)) \to  \HH^{0}(\cO_{X}(d))\to\\
&\HH^{1}(\cO_{X'}(d-e_{1}))\to \cdots .
\end{align*}
From the exactness of the top row we see that every element of $R$ 
that vanishes on $X$ is a multiple of $f_{c}$, so $f_{c}$ generates the homogeneous ideal of $X$ in $R$.
Lifting this back to the polynomial ring and using
 the inductive hypothesis, we see that $f_{1},\dots, f_{c}$ generate the homogeneous ideal of
$X$ in $S$.

Moreover, if $\dim X\geq 1$ then $\dim X' \geq 2$, so $\HH^{1}(\cO_{X'}(d-e_{1})) = 0$ for all $d$ by the induction,
whence the surjectivity statement holds for $X$.

Finally, the induction hypothesis and the exact sequences
$$
\HH^{i}(\cO_{X'}(d)) \to  \HH^{i}(\cO_{X}(d))\to \HH^{i+1}(\cO_{X'}(d-e_{1}))
$$
together show that $\HH^{i}(\cO_{X}(d)) = 0$ for $i<\dim X = \dim X'-1$.

\end{proof}

\section{Primary Decomposition and B\'ezout's Theorem}

The classic version of B\'ezout's Theorem says that plane curves of degrees $e_{1}$ and $e_{2}$ that
have no common components meet in $e_{1}e_{2}$ points, counted with multiplicity. To extend this
result to more general intersections, the language of primary decomposition is useful.

\fix{say somewhere that ``rings are commutative''}

Let $R$ be a Noetherian ring, and let $P$ be a prime ideal of $R$,
that is an ideal $P\neq R$ such that $fg\in P$ and  $f\notin P$ implies $g \in P$.
An ideal $Q\subset R$ is called \emph{P-primary} if $fg\in Q$ and $f\notin P$ implies $g \in Q$;
and $Q$ is \emph{primary} if it is $P$-primary for some (necessarily unique) prime $P$.

Let $I\subsetneq R$ be an ideal. We define $Ass(R/I)$ denote the set of prime ideals $P$ such that $P$ is the annihilator of some element of $R/I$.

Emmy Noether's primary decomposition theorem says that in this situation $Ass(R/I)$ is a finite set, 
and $I$ can be written as  
$$
I = \bigcap_{P\in Ass(R/I)} Q_{P}.
$$
where $Q_{P}$ is $P$-primary. Moreover, $Ass(R/I)$ is the unique minimal set of primes for which this is possible.

The $Q_{P}$ corresponding to the minimal elements of $Ass(R/I)$ are called \emph{isolated components} of
$I$, and they are unique; the others are called \emph{embedded components}. 

If $I \subsetneq S:=\CC[x_{0},\dots,x_{n}]$ is a homogeneous ideal, then $I$ is saturated if and only if
the maximal ideal $(x_{0}, \dots, x_{n})$ is \emph{not} in $Ass(S/I)$, and we transfer the terminology of
primary decomposition to schemes, saying that
the scheme $X := V(I)$ is the union of  subschemes $X_{i}$, where each $X_{i} = V(Q_{P_{i}})$ for some primary
component $Q_{P_{i}}$ of $I$, so that $X_{i}$ is supported on the algebraic
set $V(P_{i})$. The \emph{isolated components} of $X$ are the schemes $X_{i}$ for isolated compoents
$Q_{P_{i}}$; that is, the isolated components are those whose support is not contained in the support of any other
component; and the embedded components of $X$ are the $X_{i}$ whose supports are properly contained in the supports
of other components. For example, if
$$
I = (x_{0})\cap 
(x_{1},x_{2})\cap 
(x_{0},x_{1},x_{3}^{2}) 
\subset \CC[x_{0},\dots,x_{3}]
$$
then the the primary decomposition is the one shown. $X =V(I)$ has, as isolated components, a line and a plane,
and the plane contains an embedded point supported at the point $V(x_{0},x_{1},x_{3})$.
\fix{picture}

The first statement of the following Theorem is \cite[Exericse 8.4.6]{Fulton}.

\begin{theorem}
Let $X\subset \PP^{n}$ be a scheme defined by an ideal $(f_{1}, \dots f_{c})$, where $\deg f_{i} = e_{i}$.
If the the isolated components of $X$ are $X_{1}, \dots, X_{s}$, then 
$$
\sum_{i} \deg X_{i} \leq \prod_{i} e_{i}.
$$
Moreover, if $\codim X = c$, then equality holds and $X$ has no embedded components.
\end{theorem}

B\'ezout via Koszul complex, at least in codim 2.

\begin{fact}
 Fulton \cite[]{} shows that if $X,Y$ are any varieties, then there are algebraic cycles 
\end{fact}
\section{Families of schemes}
\fix{schemes or varieties??}

\end{document}